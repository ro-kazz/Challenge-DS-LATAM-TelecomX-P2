# Challenge-DS-LATAM-TelecomX-P2
## üéØ Objetivo de la Parte 2

1) **Preparar un dataset modelable** (todas las variables num√©ricas, sin fuga de informaci√≥n).  
2) **Enfrentar el desbalance** con t√©cnicas adecuadas (SMOTE).  
3) **Entrenar y comparar** m√∫ltiples clasificadores para predecir churn.  
4) **Evaluar** con m√©tricas robustas (F1, ROC‚ÄëAUC, PR‚ÄëCurve).  
5) **Interpretar** los modelos (coeficientes/feature importance) para decisiones de negocio.  
6) **Concluir** con acciones de retenci√≥n y un plan de despliegue.

---

## üìÇ Dataset

- `datos_preparados.csv` ‚Äî Base **limpia** con categ√≥ricas en formato `Yes/No` y otras categor√≠as nominales; `Churn` como `Yes/No` o 0/1.

> Aseg√∫rate de **eliminar `customerID`** antes del modelado (no aporta y puede sesgar).

---

## üß≠ Flujo (Roadmap ML)

**Preparaci√≥n**
- **Codificaci√≥n OHE** con `pandas.get_dummies` ‚Üí `datos_codificados` (todas las categ√≥ricas a num√©rico; `Churn` excluida de OHE).  
- **Split 70/30** estratificado: `X_train_full`, `X_test_full`, `y_train`, `y_test`.  
- **StandardScaler**: solo para modelos sensibles a escala (LogReg/KNN).  
- **Correlaciones** (en train; normalizadas por requerimiento): ranking de asociaci√≥n contra `Churn_bin`.  
- **Baseline** con `DummyClassifier (most_frequent)` para piso m√≠nimo de desempe√±o.  
- **Top‚ÄëN features** por |correlaci√≥n| (definidas **en train**, sin fuga).  
  - Conjuntos finales listos:  
    - **Escalados** ‚Üí `X_train_scaled_top`, `X_test_scaled_top` (LogReg/KNN).  
    - **Sin escalar** ‚Üí `X_train_tree_top`, `X_test_tree_top` (RF/XGB).

**Balanceo**
- **SMOTE** aplicado **solo en entrenamiento** (evita fuga), en dos espacios:  
  - `X_train_scaled_top_sm, y_train_scaled_sm` ‚Üí LogReg/KNN.  
  - `X_train_tree_top_sm,  y_train_tree_sm`  ‚Üí RF/XGB.

**Entrenamiento y comparaci√≥n**
- Modelos: **Regresi√≥n Log√≠stica**, **KNN**, **Random Forest**, **XGBoost**.  
- M√©tricas en test: **Accuracy**, **Precision**, **Recall**, **F1**, **ROC‚ÄëAUC**.  
- Visuales comparativos: **Matrices de confusi√≥n**, **ROC** y **Precision‚ÄëRecall** (`RocCurveDisplay`, `PrecisionRecallDisplay`).

**Tuning + Validaci√≥n (sin fuga)**
- Pipelines con **SMOTE/escala dentro de CV** (`StratifiedKFold` 5‚Äëfold).  
- B√∫squeda de hiperpar√°metros (Grid/Random).  
- **Diagn√≥stico 4.3**: comparar **F1 (CV)** vs **F1 (test)** para detectar **overfitting** / **underfitting**.

**Interpretaci√≥n**
- **LogReg**: coeficientes (signo/direcci√≥n).  
- **RF/XGB**: `feature_importances_`.  
- **KNN**: **Permutation Importance** (‚àÜF1 al permutar).  
- **Consenso**: normalizar importancias y promediarlas para un ranking unificado.

**Conclusiones estrat√©gicas**
- KPI: churn global. Drivers frecuentes: **contrato mensual**, **sin soporte/seguridad**, **m√©todo de pago e‚Äëcheck**, **tenure bajo**, **cargos altos**.  
- Acciones: **migraci√≥n a contratos anuales**, **bundles con soporte**, **incentivos de m√©todo de pago**, **onboarding 0‚Äì3 meses**, **step‚Äëup pricing**.  
- Roadmap de despliegue (4 semanas) con pilotos y control.

---

## üõ†Ô∏è Requisitos (librer√≠as y versiones)

Probado con:

- `pandas==2.2.2`  
- `numpy==2.0.2`  
- `matplotlib==3.10.0`  
- `seaborn==0.13.2`  
- `scikit-learn==1.6.1`  
- **Adicionales**: `imbalanced-learn` (SMOTE), `xgboost`

### Instalaci√≥n r√°pida
```bash
pip install pandas==2.2.2 numpy==2.0.2 matplotlib==3.10.0 seaborn==0.13.2 scikit-learn==1.6.1
pip install imbalanced-learn xgboost
```

### Verificar versiones del runtime
```python
import importlib, platform
for pkg in ["pandas","numpy","matplotlib","seaborn","sklearn","imblearn","xgboost"]:
    try:
        m = importlib.import_module(pkg)
        print(f"{pkg}=={getattr(m,'__version__','N/D')}")
    except Exception:
        print(f"{pkg}==NO_INSTALADO")
print("Python:", platform.python_version())
```

---

## ‚ñ∂Ô∏è Ejecuci√≥n (paso a paso)

1) Coloca `datos_preparados.csv` junto al notebook   
2) Corre las celdas en orden:  
   - OHE ‚Üí Split 70/30 ‚Üí Scaler ‚Üí Correlaciones ‚Üí Baseline ‚Üí Top‚ÄëN features ‚Üí SMOTE ‚Üí Modelos ‚Üí Tuning + CV ‚Üí Interpretaci√≥n ‚Üí Conclusiones.  
3) Usa las curvas **ROC/PR** para comparar; elige el **modelo principal** seg√∫n objetivo (Recall/F1 para retenci√≥n, ROC‚ÄëAUC para ranking).  
4) Renderiza el **Informe de Conclusiones** (celda Markdown incluida en el notebook).

---

## üìä Salidas esperadas

- Tabla `results_df` con m√©tricas de test.  
- Gr√°ficos: **confusi√≥n**, **ROC**, **Precision‚ÄëRecall**.  
- Tabla de **CV vs Test** (diagn√≥stico de over/underfitting).  
- Gr√°ficos de **importancias** y **consenso**.  
- **Informe de Conclusiones Estrat√©gicas** (Markdown).

---

## üîí Buenas pr√°cticas implementadas

- **Sin fuga**: selecci√≥n de features y correlaciones s√≥lo con **train**; SMOTE/escala **dentro de CV**.  
- **Desbalance controlado**: SMOTE aplicado **s√≥lo en train**.  
- **Trazabilidad**: baseline, modelos comparables y visuales est√°ndar.  
- **Interpretabilidad**: coeficientes, importancias, permutaci√≥n y consenso.

---

## üß± Estructura recomendada

```
.
‚îú‚îÄ‚îÄ TelecomX_P2_ML_Colab.ipynb     # Notebook PARTE 2 (ML)
‚îú‚îÄ‚îÄ datos_preparados.csv           # Dataset de entrada
‚îî‚îÄ‚îÄ README.md                      # Este documento
```



